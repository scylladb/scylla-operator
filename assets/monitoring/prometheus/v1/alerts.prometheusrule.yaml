apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name:  "{{ .scyllaDBMonitoringName }}-alerts"
  labels:
    scylla-operator.scylladb.com/scylladbmonitoring-name: "{{ .scyllaDBMonitoringName }}"
spec:
{{`
  groups:
  - name: scylla.rules
    rules:
    - alert: cqlNonPrepared
      expr: cql:non_prepared > 0
      for: 10s
      labels:
        severity: "info"
        advisor: "cqlOptimization"
        dashboard: "cql"
        description: 'Some queries are non-prepared'
        summary: non prepared statments
    - alert: cql:non_paged_no_system
      expr: cql:non_paged > 0
      for: 10s
      labels:
        severity: "info"
        advisor: "cqlOptimization"
        dashboard: "cql"
        status: "1"
        description: 'Some SELECT queries are non-paged'
        summary: non paged statments
    - alert: cqlNoTokenAware
      expr: cql:non_token_aware > 0
      for: 10s
      labels:
        severity: "info"
        advisor: "cqlOptimization"
        dashboard: "cql"
        description: 'Some queries are not token-aware'
        summary: non token aware statments
    - alert: cqlAllowFiltering
      expr: cql:allow_filtering > 0
      for: 10s
      labels:
        severity: "info"
        advisor: "cqlOptimization"
        dashboard: "cql"
        description: 'Some queries use ALLOW FILTERING'
        summary: Allow filtering queries
    - alert: cqlCLAny
      expr: cql:any_queries > 0
      for: 10s
      labels:
        severity: "info"
        advisor: "cqlOptimization"
        dashboard: "cql"
        description: 'Some queries use Consistency Level: ANY'
        summary: non prepared statments
    - alert: cqlCLAll
      expr: cql:all_queries > 0
      for: 10s
      labels:
        severity: "info"
        advisor: "cqlOptimization"
        dashboard: "cql"
        description: 'Some queries use Consistency Level: ALL'
        summary: non prepared statments
    - alert: nonBalancedcqlTraffic
      expr: abs(rate(scylla_cql_updates{conditional="no"}[1m]) - scalar(avg(rate(scylla_cql_updates{conditional="no"}[1m]))))/scalar(stddev(rate(scylla_cql_updates{conditional="no"}[1m]))+100) > 2
      for: 3m
      labels:
        severity: "info"
        status: "1"
        advisor: "balanced"
        dashboard: "cql"
        description: 'CQL queries are not balanced among shards {{ $labels.instance }} shard {{ $labels.shard }}'
        summary: CQL queries are not balanced
    - alert: nodeLocalErrors
      expr: sum(errors:local_failed) by (cluster, instance) > 0
      for: 10s
      labels:
        severity: "info"
        advisor: "operationError"
        dashboard: "scylla-detailed"
        description: 'Some operation failed at the replica side'
        summary: Replica side Level error
    - alert: nodeIOErrors
      expr: sum(rate(scylla_reactor_aio_errors[60s])) by (cluster, instance) > 0
      for: 10s
      labels:
        severity: "info"
        advisor: "operationError"
        dashboard: "OS-master"
        description: 'IO Errors can indicate a node with a faulty disk {{ $labels.instance }}'
        summary: IO Disk Error
    - alert: nodeCLErrors
      expr: sum(errors:operation_unavailable) by (cluster) > 0
      for: 10s
      labels:
        severity: "info"
        advisor: "operationError"
        dashboard: "scylla-detailed"
        description: 'Some operation failed due to consistency level'
        summary: Consistency Level error
    - alert: preparedCacheEviction
      expr: sum(rate(scylla_cql_prepared_cache_evictions[2m])) by (cluster) + sum(rate(scylla_cql_authorized_prepared_statements_cache_evictions[2m])) by (cluster) > 100
      for: 5m
      labels:
        severity: "info"
        advisor: "preparedEviction"
        dashboard: "scylla-detailed"
        description: 'The prepared-statement cache is being continuously evicted, which could indicate a problem in your prepared-statement usage logic.'
        summary: Prepared cache eviction
    - alert: heavyCompaction
      expr: max(scylla_scheduler_shares{group="compaction"}) by (cluster) >= 1000
      for: 20m
      labels:
        severity: "info"
        advisor: "heavyCompaction"
        dashboard: "scylla-detailed"
        description: 'Compaction load increases to a level it can interfere with the system behaviour. If this persists set the compaction share to a static level.'
        summary: Heavy compaction load
    - alert: shedRequests
      expr: max(sum(rate(scylla_transport_requests_shed[60s])) by (instance,cluster)/sum(rate(scylla_transport_requests_served{}[60s])) by (instance, cluster)) by(cluster) > 0.01
      for: 5m
      labels:
        severity: "info"
        advisor: "systemOverload"
        dashboard: "scylla-detailed"
        description: 'More than 1% of the requests got shed, this is an indication of an overload, consider system resize.'
        summary: System is overloaded
    - alert: cappedTombstone
      expr: changes(scylla_sstables_capped_tombstone_deletion_time[1h]) > 0
      for: 1m
      labels:
        severity: "info"
        advisor: "cappedTombstone"
        dashboard: "scylla-detailed"
        description: 'Tombstone delete time was set too far in the future and was capped'
        summary: Tobmstone delete time is capped
    - alert: InstanceDown
      expr: up{job="scylla"} == 0
      for: 30s
      labels:
        severity: "warn"
      annotations:
        description: '{{ $labels.instance }} has been down for more than 30 seconds.'
        summary: Instance {{ $labels.instance }} down
    - alert: InstanceDown
      expr: sum(up{job="scylla"}>0)by(instance) unless sum(scylla_transport_requests_served{shard="0"}) by(instance)
      for: 1m
      labels:
        severity: "warn"
      annotations:
        description: '{{ $labels.instance }} instance is shutting down.'
        summary: Instance {{ $labels.instance }} down
    - alert: InstanceDown
      expr: scylla_node_operation_mode > 3
      for: 30s
      labels:
        severity: "warn"
      annotations:
        description: '{{ $labels.instance }} instance is shutting down.'
        summary: Instance {{ $labels.instance }} down
    - alert: DiskFull
      expr: node_filesystem_avail_bytes{mountpoint="/var/lib/scylla"} / node_filesystem_size_bytes{mountpoint="/var/lib/scylla"}
        * 100 < 35
      for: 30s
      labels:
        severity: "warn"
      annotations:
        description: '{{ $labels.instance }} has less than 35% free disk space.'
        summary: Instance {{ $labels.instance }} low disk space
    - alert: DiskFull
      expr: node_filesystem_avail_bytes{mountpoint="/var/lib/scylla"} / node_filesystem_size_bytes{mountpoint="/var/lib/scylla"}
        * 100 < 25
      for: 30s
      labels:
        severity: "error"
      annotations:
        description: '{{ $labels.instance }} has less than 25% free disk space.'
        summary: Instance {{ $labels.instance }} low disk space
    - alert: DiskFull
      expr: node_filesystem_avail_bytes{mountpoint="/var/lib/scylla"} / node_filesystem_size_bytes{mountpoint="/var/lib/scylla"}
        * 100 < 15
      for: 30s
      labels:
        severity: "critical"
      annotations:
        description: '{{ $labels.instance }} has less than 15% free disk space.'
        summary: Instance {{ $labels.instance }} low disk space
    - alert: DiskFull
      expr: node_filesystem_avail_bytes{mountpoint="/"} / node_filesystem_size_bytes{mountpoint="/"}
        * 100 < 20
      for: 30s
      labels:
        severity: "error"
      annotations:
        description: '{{ $labels.instance }} has less than 20% free disk space on the root partition.'
        summary: Instance {{ $labels.instance }} low disk space
    - alert: NoCql
      expr: scylla_manager_healthcheck_cql_status == -1
      for: 30s
      labels:
        severity: "warn"
      annotations:
        description: '{{ $labels.host }} has denied CQL connection for more than 30 seconds.'
        summary: Instance {{ $labels.host }} no CQL connection
    - alert: HighLatencies
      expr: wlatencyp95{by="instance"} > 100000
      for: 5m
      labels:
        severity: "info"
      annotations:
        description: '{{ $labels.instance }} has 95% high latency for more than 5 minutes.'
        summary: Instance {{ $labels.instance }} High Write Latency
    - alert: HighLatencies
      expr: wlatencya{by="instance"} >10000
      for: 5m
      labels:
        severity: "info"
      annotations:
        description: '{{ $labels.instance }} has average high latency for more than 5 minutes.'
        summary: Instance {{ $labels.instance }} High Write Latency
    - alert: HighLatencies
      expr: rlatencyp95{by="instance"} > 100000
      for: 5m
      labels:
        severity: "info"
      annotations:
        description: '{{ $labels.instance }} has 95% high latency for more than 5 minutes.'
        summary: Instance {{ $labels.instance }} High Read Latency
    - alert: HighLatencies
      expr: rlatencya{by="instance"} >10000
      for: 5m
      labels:
        severity: "info"
      annotations:
        description: '{{ $labels.instance }} has average high latency for more than 5 minutes.'
        summary: Instance {{ $labels.instance }} High Read Latency
    - alert: BackupFailed
      expr: (sum(scylla_manager_scheduler_run_total{type=~"backup", status="ERROR"}) or vector(0)) - (sum(scylla_manager_scheduler_run_total{type=~"backup", status="ERROR"} offset 3m) or vector(0)) > 0
      for: 10s
      labels:
        severity: "info"
      annotations:
        description: 'Backup failed'
        summary: Backup task failed
    - alert: RepairFailed
      expr: (sum(scylla_manager_scheduler_run_total{type=~"repair", status="ERROR"}) or vector(0)) - (sum(scylla_manager_scheduler_run_total{type=~"repair", status="ERROR"} offset 3m) or vector(0)) > 0
      for: 10s
      labels:
        severity: "info"
      annotations:
        description: 'Repair failed'
        summary: Repair task failed
    - alert: restart
      expr: resets(scylla_gossip_heart_beat[1h])>0
      for: 10s
      labels:
        severity: "info"
      annotations:
        description: 'Node restarted'
        summary: Instance {{ $labels.instance }} restarted
    - alert: oomKill
      expr: changes(node_vmstat_oom_kill[1h])>0
      for: 10s
      labels:
        severity: "warn"
      annotations:
        description: 'OOM Kill on {{ $labels.instance }}'
        summary: A process was terminated on Instance {{ $labels.instance }}
    - alert: tooManyFiles
      expr: (node_filesystem_files - node_filesystem_files_free) / on(instance) group_left count(scylla_reactor_cpu_busy_ms) by (instance)>20000
      for: 10s
      labels:
        severity: "info"
        description: 'Over 20k open files per shard {{ $labels.instance }}'
        summary: There are over 20K open files per shard on Insace {{ $labels.instance }}
    - alert: tooManyFiles
      expr: (node_filesystem_files - node_filesystem_files_free) / on(instance) group_left count(scylla_reactor_cpu_busy_ms) by (instance)>30000
      for: 10s
      labels:
        severity: "warn"
        description: 'Over 30k open files per shard {{ $labels.instance }}'
        summary: There are over 30K open files per shard on Insace {{ $labels.instance }}
    - alert: tooManyFiles
      expr: (node_filesystem_files - node_filesystem_files_free) / on(instance) group_left count(scylla_reactor_cpu_busy_ms) by (instance)>40000
      for: 10s
      labels:
        severity: "error"
        description: 'Over 40k open files per shard {{ $labels.instance }}'
        summary: There are over 40K open files per shard on Insace {{ $labels.instance }}
`}}
