# ScyllaClusters

## Introduction

[ScyllaCluster](../../reference/api/groups/scylla.scylladb.com/scyllaclusters.rst) defines a ScyllaDB **datacenter** and manages the racks within.
This section aims to make you familiar with how it looks like and how to perform some of the basic configuration or accessing the APIs.
By no means is this a complete description of what it can do. Please consult our [generated API reference](../../reference/api/groups/scylla.scylladb.com/scyllaclusters.rst) for a complete list of options.

::::{tip}
You can always see the currently supported API fields for a particular version installed in your cluster by running
:::{code}
kubectl explain --api-version='scylla.scylladb.com/v1' ScyllaCluster.spec
:::
::::

Note that the Kubernetes clusters are only a regional concept, availability-wise they map into a ScyllaDB datacenter.
To deploy a ScyllaDB cluster with multiple datacenters use our multi datacenter resource [ScyllaDBCluster](../scylladbclusters/scylladbclusters.md), or combine multiple Kubernetes clusters, each running a [ScyllaCluster](../../reference/api/groups/scylla.scylladb.com/scyllaclusters.rst),
To learn more about **manual** multi-dc deployments using ScyllaCluster resource, please see [the dedicated multi-datacenter guide](./multidc/multidc.md).

## Creating a ScyllaCluster

Before we go and create the ScyllaCluster, we'll first create our ScyllaDB config file that we'll reference later in the ScyllaCluster definition.

:::{code-block} bash
:linenos:
:emphasize-lines: 7

kubectl apply --server-side -f=- <<EOF
apiVersion: v1
kind: ConfigMap
metadata:
  name: scylladb-config
data:
  scylla.yaml: |
    authenticator: PasswordAuthenticator
    authorizer: CassandraAuthorizer
    # Other options
EOF
:::

:::{note}
Some of the ScyllaDB config is also generated by the {{productName}} based on your ScyllaCluster definition.
While you shall not define conflicting options here ({{productName}} config wins), we still want to give you a reasonable control to fine tune some ScyllaDB knobs.
IOW, please stay away from touching networking, listen or published addresses and so on, but feel free to tune buffer sizes and such.
:::

Now we can create a simple ScyllaCluster to get ScyllaDB running.

:::{include} ../../.internal/rf-warning.md
:::

:::{code-block} bash
:linenos:
:substitutions:

kubectl apply --server-side -f=- <<EOF
apiVersion: scylla.scylladb.com/v1
kind: ScyllaCluster
metadata:
  name: scylladb
spec:
  repository: {{imageRepository}}
  version: {{scyllaDBImageTag}}
  agentVersion: {{agentVersion}}
  developerMode: false
  automaticOrphanedNodeCleanup: true
  datacenter:
    name: us-east-1
    racks:
    - name: us-east-1a
      members: 1
      scyllaConfig: scylladb-config
      storage:
        capacity: 100Gi
        storageClassName: scylladb-local-xfs
      resources:
        requests:
          cpu: 1
          memory: 8Gi
        limits:
          cpu: 1
          memory: 8Gi
      placement:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: topology.kubernetes.io/zone
                operator: In
                values:
                - us-east-1a 
              - key: scylla.scylladb.com/node-type
                operator: In
                values:
                - scylla
        tolerations:
        - key: scylla-operator.scylladb.com/dedicated
          operator: Equal
          value: scyllaclusters
          effect: NoSchedule
    - name: us-east-1b
      members: 1
      scyllaConfig: scylladb-config
      storage:
        capacity: 100Gi
        storageClassName: scylladb-local-xfs
      resources:
        requests:
          cpu: 1
          memory: 8Gi
        limits:
          cpu: 1
          memory: 8Gi
      placement:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: topology.kubernetes.io/zone
                operator: In
                values:
                - us-east-1b
              - key: scylla.scylladb.com/node-type
                operator: In
                values:
                - scylla
        tolerations:
        - key: scylla-operator.scylladb.com/dedicated
          operator: Equal
          value: scyllaclusters
          effect: NoSchedule
    - name: us-east-1c
      members: 1
      scyllaConfig: scylladb-config
      storage:
        capacity: 100Gi
        storageClassName: scylladb-local-xfs
      resources:
        requests:
          cpu: 1
          memory: 8Gi
        limits:
          cpu: 1
          memory: 8Gi
      placement:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: topology.kubernetes.io/zone
                operator: In
                values:
                - us-east-1c
              - key: scylla.scylladb.com/node-type
                operator: In
                values:
                - scylla
        tolerations:
        - key: scylla-operator.scylladb.com/dedicated
          operator: Equal
          value: scyllaclusters
          effect: NoSchedule
EOF
:::

:::{note}
Values in these examples are only illustratory.
You should always adjust the resources and storage capacity depending on your needs or the size and the type of your Kubernetes nodes.
Similarly, the tolerations will differ depending on how and whether you set up dedicated node pools, or the placement if you want to set affinity for your rack to an availability zone or a failure domain.
:::

:::{include} ../../.internal/tuning-qos-caution.md
:::

::::{note}
:name: scyllacluster-enterprise
{{productName}} works with both ScyllaDB Open Source and ScyllaDB Enterprise.
You only have to adjust the [repository and tag fields](api-scylla.scylladb.com-scyllaclusters-v1-.spec) for each ScyllaCluster.

In addition to it, if you want to use tuning from the Enterprise repository, you have to adjust [**scyllaUtilsImage** on the global ScyllaOperatorConfig/cluster](../scyllaoperatorconfigs.md#tuning-with-scylladb-enterprise).

:::{code-block} bash
:linenos:
:substitutions:
:emphasize-lines: 6,7

apiVersion: scylla.scylladb.com/v1
kind: ScyllaCluster
metadata:
  name: scylladb
spec:
  repository: {{enterpriseImageRepository}}
  version: {{scyllaDBImageTag}}
  # ...
EOF
:::

::::

Wait for it to deploy by watching status conditions.
:::{include} ./../../.internal/wait-for-status-conditions.scyllacluster.code-block.md
:::

## IPv6 and Dual-Stack Networking

You can run ScyllaDB clusters on IPv6-only networks or use both IPv4 and IPv6 together (dual-stack).

### IPv6 Configuration

Configure IPv6 using the `network` field to specify which IP version ScyllaDB should use:

```yaml
apiVersion: scylla.scylladb.com/v1
kind: ScyllaCluster
metadata:
  name: scylla-ipv6
spec:
  version: {{scyllaDBImageTag}}
  
  network:
    ipFamilies:
      - IPv6
    ipFamilyPolicy: SingleStack
    dnsPolicy: ClusterFirst
    
  datacenter:
    name: dc1
    racks:
    - name: rack1
      members: 3
      storage:
        capacity: 10Gi
      resources:
        requests:
          cpu: 1
          memory: 4Gi
  exposeOptions:
    broadcastOptions:
      nodes:
        type: PodIP
      clients:
        type: PodIP
```

### Dual-Stack Configuration

For dual-stack environments (both IPv4 and IPv6), specify both IP families with the primary one first:

```yaml
apiVersion: scylla.scylladb.com/v1
kind: ScyllaCluster
metadata:
  name: scylla-dual-stack
spec:
  version: {{scyllaDBImageTag}}
  
  network:
    ipFamilies:
      - IPv4
      - IPv6
    ipFamilyPolicy: PreferDualStack
    dnsPolicy: ClusterFirst
    
  datacenter:
    name: dc1
    racks:
    - name: rack1
      members: 3
      storage:
        capacity: 10Gi
      resources:
        requests:
          cpu: 1
          memory: 4Gi
  exposeOptions:
    broadcastOptions:
      nodes:
        type: PodIP
      clients:
        type: PodIP
```

### What happens by default

::::{important}
**DNS Configuration for IPv6**

When using IPv6, it's recommended to explicitly set `dnsPolicy: ClusterFirst` in the network configuration:

```yaml
spec:
  network:
    dnsPolicy: ClusterFirst
```

This will make sure proper IPv6 DNS resolution within the Kubernetes cluster, which is essential for ScyllaDB nodes to discover each other using IPv6 addresses.
::::

::::{important}
**If you don't specify IP families, ScyllaCluster will use IPv4 by default:**

- **IPv4-only clusters**: Uses IPv4 (default behavior)
- **IPv6-only clusters**: Set `network.ipFamilies: [IPv6]`
- **Dual-stack clusters**: Set both families with primary first, e.g., `network.ipFamilies: [IPv4, IPv6]`

This means existing clusters keep working without any changes.
::::

### Configuration Options

| Field | What it does | Default | Required? |
|-------|-------------|---------|-----------|
| `network.ipFamilies` | IP versions for ScyllaDB and services (first is primary) | `["IPv4"]` | **Recommended** for IPv6 |
| `network.ipFamilyPolicy` | How services handle IP versions | `SingleStack` | Only for advanced dual-stack |

::::{note}
**When do you need explicit `network` configuration?**

- **IPv6-only**: Set `network.ipFamilies: [IPv6]` and `network.ipFamilyPolicy: SingleStack`
- **Dual-stack**: Set `network.ipFamilies: [IPv4, IPv6]` (or reverse order) and `network.ipFamilyPolicy: PreferDualStack`
- **IPv4-only (default)**: No configuration needed
::::

For detailed configuration, troubleshooting, and examples, see the [IPv6 networking documentation](../../management/networking/ipv6/index.md).

## Forcing a rolling restart

When you change a ScyllaDB config option that's not live reloaded by ScyllaDB, or want to trigger a rolling restart for a different reason, ScyllaCluster allows triggering the rolling restarts declaratively by changing `ScyllaCluster.spec.forceRedeploymentReason` to any other value. This will trigger a rolling restart of all ScyllaDB nodes in sequence, always respecting the [PodDistruptionsBudget](https://kubernetes.io/docs/concepts/workloads/pods/disruptions/#pod-disruption-budgets) and keeping the cluster available.

## Spreading racks over availability zones

ScyllaCluster give you the freedom to chose how you want to spread you rack over your Kubernetes nodes with generic [placement options](api-scylla.scylladb.com-scyllaclusters-v1-.spec.datacenter.racks[].placement).
Here is a quick example of how you'd use them to spread your racks across different availability zone:

:::{include} ../../.internal/rf-warning.md
:::

:::::{tabs}

::::{group-tab} GKE
:::{code} yaml
spec:
  datacenter:
    name: <dc_name>
    racks:
    - name: <rack_name>
      placement:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: failure-domain.beta.kubernetes.io/zone
                operator: In
                values:
                - <gcp_zone>
:::
::::

::::{group-tab} EKS
:::{code} yaml
spec:
  datacenter:
    name: <dc_name>
    racks:
    - name: <rack_name>
      placement:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: topology.kubernetes.io/zone
                operator: In
                values:
                - <aws_zone>
:::
::::

:::::

## Next steps

To follow up with other advanced topics, see [the section index for options](./index.md).
